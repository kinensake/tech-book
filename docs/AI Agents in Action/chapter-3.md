---
sidebar_position: 12
---

# 3 Engaging GPT assistants

### This chapter covers

- Introducing the OpenAI GPT Assistants platform and the ChatGPT UI
- Building a GPT that can use the code interpretation capabilities
- Extending an assistant via custom actions
- Adding knowledge to a GPT via file uploads
- Commercializing your GPT and publishing it to the GPT Store

As we explore the OpenAI crusade into assistants and what has been hinted at, ultimately, an agent platform called GPT Assistants, we’ll introduce GPT assistants through the ChatGPT interface. Then, we’ll add in several fully developed assistants that can suggest recipes from ingredients, fully analyze data as a data scientist, guide readers through books, and be extended with custom actions. By the end of the chapter, we’ll be ready to build a fully functional agent that can be published to the OpenAI GPT Store.

## 3.1 Exploring GPT assistants through ChatGPT

ChatGPT (ChatGPT Plus, at the time of writing) allows you to build GPT assistants, consume other assistants, and even publish them, as you’ll see by the end of the chapter. When OpenAI announced the release of the GPT Assistants platform, it helped define and solidify the emergence of AI agents. As such, it’s worth a serious review by anyone interested in building and consuming agent systems. First, we’ll look at building GPT assistants through ChatGPT Plus, which requires a premium subscription. If you don’t want to purchase a subscription, browse this chapter as a primer, and chapter 6 will demonstrate consuming the API service later.

Figure 3.1 shows the page for the GPT Store within ChatGPT ([https://chatgpt.com/gpts](https://chatgpt.com/gpts)). From here, you can search and explore various GPTs for virtually any task. The amount of usage will typically indicate how well each GPT works, so gauge which works best for you.

![figure](assets/3-1.png)

##### Figure 3.1 The main interface to the GPT Store

Creating your first GPT Assistant is as simple as clicking the Create button and following along with the GPT Builder chat interface. Figure 3.2 shows using the Builder to create a GPT. Working through this exercise a couple of times can be a great way to start understanding an assistant’s requirements.

![figure](assets/3-2.png)

##### Figure 3.2 Interacting with the GPT Builder to create an assistant

After working with the Builder, you can open the manual configuration panel, shown in figure 3.3, and edit the GPT directly. You’ll see the name, description, instructions, and conversation starters populated from your conversations with the Builder. This can be a great start, but generally, you’ll want to edit and tweak these properties manually.

![figure](assets/3-3.png)

##### Figure 3.3 The Configure panel of the GPT Assistants platform interface

If you want to follow along with building your own Culinary Companion, enter the text from listing 3.1 into the instructions. These instructions were partly generated by conversing with the Builder and added based on explicit outputs. The explicit outputs are added to the instructions as rules.

##### Listing 3.1 Instructions for Culinary Companion

```
Culinary Companion assists users with a friendly, engaging tone, 
reminiscent of the famous chef Julia Child.     #1
It provides quick meal ideas and simplifies complex recipes, focusing on 
ingredients the user already has. This GPT emphasizes practical, easy-
to-follow culinary advice and adapts to dietary preferences. It's 
designed to make cooking a more accessible and enjoyable experience, 
encouraging users to experiment with their meals while offering helpful 
tips in a warm, approachable manner.     #2

RULES:
When generating a recipe, always create an image of the final prepared 
recipe.                                                                   #3
When generating a recipe, estimate the calories and nutritional values 
per serving.                                                             
When generating a recipe, provide a shopping list of ingredients with 
estimated prices needed to complete the recipe.                          
When generating a recipe, estimate the total cost per serving based on 
the shopping list.
```

#1 Personality or persona of your assistant  
#2 General guidelines of the agent’s role and goal  
#3 A set of rules the agent will follow when suggesting a recipe

Defining rules for an assistant/agent essentially creates a template for what the agent will produce. Adding rules ensures that the GPT output is consistent and aligned with your expectations of how the agent should operate. Defining and giving an agent/ assistant a persona provides them with a unique and memorable personality.

Note  Giving an agent/assistant a particular personality can make a difference in the type and form of output. Asking a cooking agent to speak as the first celebrity chef, Julia Child, not only provides for a fun tone but also engages more references that may mention or talk about her cooking style and teaching. When constructing an agent/assistant, assigning a particular persona/personality can be helpful.

With just these few steps, we have a culinary companion that not only gives us recipes for ingredients we have on hand but also generates an image of the finished recipe, estimates the nutritional value, creates a shopping list with an estimate of prices, and breaks down the cost per serving.

Try the assistant by requesting a recipe and providing a list of ingredients you have or prefer. Listing 3.2 shows an example of a simple request with extra information to set the mood. Of course, you can add any ingredients or situations you like and then see the results.

##### Listing 3.2 Prompting the recipe

```
I have a bag of prepared frozen chicken strips and I want to make a 
romantic dinner for two.
```

Figure 3.4 shows the formatted output results from the GPT provided by the prompt. It certainly looks good enough to eat. All of this output was generated because of the instructions we provided the agent.

![figure](assets/3-4.png)

##### Figure 3.4 The output results of the Culinary Companion GPT

While the output results look great, they may not all be factual and correct, and your results may vary. For instance, the GPT added chicken strips to the shopping list when we had already suggested having those ingredients. Furthermore, the prices and estimated nutritional information are just estimates, but this can be resolved later if they interest you.

Out of the box, though, GPT Assistants is quite impressive for quickly building a proof-of-concept assistant or agent. As you’ll see later in the chapter, it also provides an excellent platform for consuming assistants outside ChatGPT. In the next section, we’ll look at more impressive features GPTs provide, such as file uploads and code interpretation.

## 3.2 Building a GPT that can do data science

The GPT Assistants platform has and will likely be extended to include various agent components. Currently, GPT Assistants support what is referred to as knowledge, memory, and actions. In chapter 8, we’ll discuss the details of knowledge and memory, and in chapter 5, we cover the concept of tool use through actions.

In our next exercise, we’ll build an assistant to perform a first-pass data science review of any CSV document we provide. This agent will use the ability or action that allows for coding and code interpretation. When you enable code interpretation, the assistant will allow file uploads by default.

Before we do that, though, we want to design our agent, and what better way to do that than to ask an LLM to build us an assistant? Listing 3.3 shows the prompt requesting ChatGPT (GPT-4) to design a data science assistant. Notice how we’re not asking for everything in a single prompt but instead iterating over the information returned by the LLM.

##### Listing 3.3 Prompting for a data science assistant

```
FIRST PROMPT:    
what is a good basic and interesting data science 
experiment you can task someone with a single 
csv file that contains interesting data?     #1
SECOND PROMPT:    
okay, can you now write all those steps into instructions 
to be used for a GPT Agent (LLM agent) to replicate all of 
the above steps      #2

THIRD PROMPT:    
What is a famous personality that can embody the agent 
data scientist and be able to present data to users?      #3
```

#1 First, ask the LLM to set the foundation.  
#2 Then, ask the LLM to convert the previous steps to a more formal process.  
#3 Finally, ask the LLM to provide a personality that can represent the process.

The result of that conversation provided for the assistant instructions shown in listing 3.4. In this case, the assistant was named Data Scout, but feel free to name your assistant what appeals to you.

##### Listing 3.4 Data Scout instructions

```
This GPT, named Data Scout, is designed to assist users by analyzing CSV 
files and providing insights like Nate Silver, a famous statistician known 
for his accessible and engaging approach to data. Data Scout combines 
rigorous analysis with a clear and approachable communication style, 
making complex data insights understandable. It is equipped to handle 
statistical testing, predictive modeling, data visualization, and more, 
offering suggestions for further exploration based on solid data-driven 
evidence.

Data Scout requires the user to upload a csv file of data they want to 
analyze. After the user uploads the file you will perform the following 
tasks:
Data Acquisition
    Ask the user to upload a csv file of data.
    Instructions: Use the pandas library to read the data from the CSV 
file. Ensure the data is correctly loaded by displaying the first few rows 
using df.head().

2. Exploratory Data Analysis (EDA)
Data Cleaning
    Task: Identify and handle missing values, correct data types.
    Instructions: Check for missing values using df.isnull().sum(). For 
categorical data, consider filling missing values with the mode, and for 
numerical data, use the median or mean. Convert data types if necessary 
using df.astype().

Visualization
    Task: Create visualizations to explore the data.
    Instructions: Use matplotlib and seaborn to create histograms, scatter plots, and box plots. For example, use sns.histplot() for histograms and 
sns.scatterplot() for scatter plots.

Descriptive Statistics
    Task: Calculate basic statistical measures.
    Instructions: Use df.describe() to get a summary of the statistics and 
df.mean(), df.median() for specific calculations.

3. Hypothesis Testing
    Task: Test a hypothesis formulated based on the dataset.
    Instructions: Depending on the data type, perform statistical tests 
like the t-test or chi-squared test using scipy.stats. For example, use 
stats.ttest_ind() for the t-test between two groups.

4. Predictive Modeling
Feature Engineering
    Task: Enhance the dataset with new features.
    Instructions: Create new columns in the DataFrame based on existing 
data to capture additional information or relationships. Use operations 
like df['new_feature'] = df['feature1'] / df['feature2'].

Model Selection
    Task: Choose and configure a machine learning model.
    Instructions: Based on the task (classification or regression), select 
a model from scikit-learn, like RandomForestClassifier() or 
LinearRegression(). Configure the model parameters.

Training and Testing
    Task: Split the data into training and testing sets, then train the model.
    Instructions: Use train_test_split from scikit-learn to divide the 
data. Train the model using model.fit(X_train, y_train).

Model Evaluation
    Task: Assess the model performance.
    Instructions: Use metrics like mean squared error (MSE) or accuracy. 
Calculate these using metrics.mean_squared_error(y_test, y_pred) or 
metrics.accuracy_score(y_test, y_pred).

5. Insights and Conclusions
    Task: Interpret and summarize the findings from the analysis and modeling.
    Instructions: Discuss the model coefficients or feature importances. 
Draw conclusions about the hypothesis and the predictive analysis. Suggest 
real-world implications or actions based on the results.

6. Presentation
    Task: Prepare a report or presentation.
    Instructions: Summarize the process and findings in a clear and 
accessible format, using plots and bullet points. Ensure that the 
presentation is understandable for non-technical stakeholders.
```

After generating the instructions, you can copy and paste them into the Configure panel in figure 3.5. Be sure to give the assistant the Code Interpretation tool (skill) by selecting the corresponding checkbox. You don’t need to upload files here; the assistant will allow file uploads when the Code Interpretation checkbox is enabled.

![figure](assets/3-5.png)

##### Figure 3.5 Turning on the Code Interpreter tool/skill

Now, we can test the assistant by uploading a CSV file and asking questions about it. The source code folder for this chapter contains a file called `netflix_titles.csv`; the top few rows are summarized in listing 3.5. Of course, you can use any CSV file you want, but this exercise will use the Netflix example. Note that this dataset was downloaded from Kaggle, but you can use any other CSV if you prefer.

##### Listing 3.5 `netflix_titles.csv` (top row of data)

```
show_id,type,title,director,cast,country,date_added,
release_year,rating,duration,listed_in,description     #1
s1,Movie,Dick Johnson Is Dead,Kirsten Johnson,, 
United States,"September 25, 2021",2020,PG-13,90 min,
Documentaries,"As her father nears the end of his life, 
filmmaker Kirsten Johnson stages his death in inventive 
and comical ways to help them both face the inevitable."     #2
```

#1 Comma-separated list of columns  
#2 An example row of data from the dataset

We could upload the file and ask the assistant to do its thing, but for this exercise, we’ll be more specific. Listing 3.6 shows the prompt and uploading the file to engage the assistant (including `Netflix_titles.csv` in the request). This example filters the results to Canada, but you can, of course, use any country you want to view.

##### Listing 3.6 Prompting the Data Scout

```
Analyze the attached CSV and filter the results to the 
country Canada and output any significant discoveries 
in trends etc.     #1
```

#1 You can select a different country to filter the data on.

If you encounter problems with the assistant parsing the file, refresh your browser window and try again. Depending on your data and filter, the assistant will now use the Code Interpreter as a data scientist would to analyze and extract trends in the data.

Figure 3.6 shows the output generated for the prompt in listing 3.5 using the `netflix_titles.csv` file for data. Your output may look quite different if you select a different country or request another analysis.

![figure](assets/3-6.png)

##### Figure 3.6 The output generated by the assistant as it analyzed the CSV data

The data science plots the assistant is building are created by writing and executing code with the Code Interpreter. You can try this with other CSV files or, if you want, different forms of data to analyze. You could even continue iterating with the assistant to update the plots visually or analyze other trends.

Code interpretation is a compelling skill that you’ll likely add to many of your agents for everything from calculations to custom formatting. In the next section, we look at how to extend the capabilities of a GPT through custom actions.

## 3.3 Customizing a GPT and adding custom actions

In our next exercise, we’ll demonstrate the use of custom actions, which can significantly extend the reach of your assistant. Adding custom actions to an agent requires several components, from understanding the OpenAPI specification endpoint to connecting to a service. Therefore, before we add custom actions, we’ll build another GPT in the next section to assist us.

### 3.3.1 Creating an assistant to build an assistant

Given GPTs’ capabilities, it only makes sense that we use one to assist in building others. In this section, we’ll build a GPT that can help us create a service we can connect as a custom action to another GPT. And yes, we’ll even use an LLM to begin constructing our helper GPT.

The following listing shows the prompt for creating the instructions for our helper GPT. This prompt is intended to generate the instructions for the assistant.

##### Listing 3.7 Prompting the helper design (in GPT Builder or ChatGPT)

```
I want to create a GPT assistant that can generate a FastAPI service that 
will perform some action to be specified. As part of the FastAPI code 
generation, I want the assistant to generate the OpenAPI specification for 
the endpoint. Please outline a set of instructions for this agent.
```

Listing 3.8 shows the bulk of the instructions generated for the prompt. The output was then modified and slightly updated with specific information and other details. Copy and paste those instructions from the file (`assistant_builder.txt`) into your GPT. Be sure to select the Code Interpreter capability also.

##### Listing 3.8 Custom action assistant instructions

```
This GPT is designed to assist users in generating FastAPI services 
tailored to specific actions, complete with the corresponding OpenAPI 
specifications for the endpoints. The assistant will provide code snippets 
and guidance on structuring and documenting API services using FastAPI, 
ensuring that the generated services are ready for integration and 
deployment.

1.   Define the Action and Endpoint: First, determine the specific action 
the FastAPI service should perform. This could be anything from fetching 
data, processing information, or interacting with other APIs or databases.

2.    Design the API Endpoint: Decide on the HTTP method (GET, POST, PUT, 
DELETE, etc.) and the endpoint URI structure. Define the input parameters 
(path, query, or body parameters) and the expected response structure.

3. Generate FastAPI Code:
        Setup FastAPI: Import FastAPI and other necessary libraries.
        Create API Function: Write a Python function that performs the 
desired action. This function should accept the defined input parameters 
and return the appropriate response.
4. Decorate the Function: Use FastAPI's decorators (e.g., 
@app.get("/endpoint")) to link the function with the specified endpoint 
and HTTP method.
        Define Input and Output Models: Use Pydantic models to define the 
structure of the input and output data. This ensures validation and 
serialization of the data.

5. Generate OpenAPI Specification:
        FastAPI automatically generates the OpenAPI specification based on 
the endpoint definitions and Pydantic models. Ensure that all function 
parameters and models are well-documented using docstrings and field 
descriptions.
        Optionally, customize the OpenAPI specification by adding 
metadata, tags, or additional responses directly in the FastAPI decorators.

6. Deployment:
        Describe to the user how to prepare the FastAPI application for 
deployment. 
        Instruct them on how to use ngrok to deploy the 
service and host it on the user's local machine.      #1
```

#1 This uses ngrok as an example to deploy the service locally.

After preparing the assistant, ensure everything is set in the Configure panel (including setting the Code Interpreter checkbox), and then refresh your browser window. This will prepare the assistant for a new session. You can request the kind of service you want to build from here.

Listing 3.9 shows the request to the Custom Action Assistant to create a daily task endpoint. If you understand how APIs work, you can suggest other options, such as `POST`. Of course, you can also ask the assistant to guide you and create your service.

##### Listing 3.9 Prompt requesting task endpoint service

```
I want to define a GET endpoint that replies with my list of daily tasks
```

After you enter the prompt, the assistant will generate the code and instructions for creating and running the FastAPI endpoint. The following listing shows an example of the code generated from the previous request.

##### Listing 3.10 `daily_tasks_api.py` (generated from assistant)

```
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List

app = FastAPI()

class Task(BaseModel):    #1
    id: int
    description: str
    completed: bool

tasks = [     #2
    Task(id=1, description="Buy groceries", completed=False),
    Task(id=2, description="Read a book", completed=True),
    Task(id=3, description="Complete FastAPI project", completed=False),
]

@app.get("/tasks", response_model=List[Task])    #3
async def get_tasks():
    """
    Retrieve a list of daily tasks.
    """
    return tasks
```

#1 Use Pydantic to create a type for the task.  
#2 This is a static list of tasks to demonstrate.  
#3 The tasks endpoint

Enter the code into Visual Studio Code (VS Code), and confirm that `fastapi` and `uvicorn` are installed with `pip`. Then, run the API using the command shown in the following listing, which runs the API in the chapter source file.

##### Listing 3.11 Running the API

```
uvicorn daily_tasks_api:app –reload      #1
```

#1 Change the name of the module/file if you’re using something different.

Open a browser to http://127.0.0.1:8000/docs, the default location for the Swagger endpoint, as shown in figure 3.7.

![figure](assets/3-7.png)

##### Figure 3.7 Navigating the Swagger docs and getting the openapi.json document

Clicking the `/openapi.json` link will display the OpenAPI specification for the endpoint, as shown in listing 3.12 (JSON converted to YAML). You’ll need to copy and save this document for later use when setting up the custom action on the agent. The endpoint produces JSON, but you can also use specifications written in YAML.

##### Listing 3.12 OpenAPI specification for the task API

```
openapi: 3.1.0
info:
  title: FastAPI
  version: 0.1.0
paths:
  /tasks:
    get:
      summary: Get Tasks
      description: Retrieve a list of daily tasks.
      operationId: get_tasks_tasks_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Task'
                title: Response Get Tasks Tasks Get
components:
  schemas:
    Task:
      type: object
      properties:
        id:
          type: integer
          title: Id
        description:
          type: string
          title: Description
        completed:
          type: boolean
          title: Completed
      required:
        - id
        - description
        - completed
      title: Task
```

Before connecting an assistant to the service, you must set up and use ngrok to open a tunnel to your local machine running the service. Prompt the GPT to provide the instructions and help you set up ngrok, and run the application to open an endpoint to port 8000 on your machine, as shown in listing 3.13. If you change the port or use a different configuration, you must update it accordingly.

##### Listing 3.13 Running ngrok (following the instructions setup)

```
./ngrok authtoken <YOUR_AUTHTOKEN>      #1
./ngrok http 8000      #2
```

#1 Enter your auth token obtained from ngrok.com.  
#2 Opens a tunnel on port 8000 to external internet traffic

After you run ngrok, you’ll see an external URL that you can now use to access the service on your machine. Copy this URL for later use when setting up the assistant. In the next section, we’ll create the assistant that consumes this service as a custom action.

### 3.3.2 Connecting the custom action to an assistant

With the service up and running on your machine and accessible externally via the ngrok tunnel, we can build the new assistant. This time, we’ll create a simple assistant to help us organize our daily tasks, where the tasks will be accessible from our locally running task service.

Open the GPT interface and the Configure panel, and copy and paste the instructions shown in listing 3.14 into the new assistant. Be sure to name the assistant and enter a helpful description as well. Also, turn on the Code Interpreter capability to allow the assistant to create the final plot, showing the tasks.

##### Listing 3.14 Task Organizer (`task_organizer_assistant.txt`)

```
Task Organizer is designed to help the user prioritize their daily tasks 
based on urgency and time availability, providing structured guidance on 
how to categorize tasks by urgency and suggesting optimal time blocks for 
completing these tasks. It adopts a persona inspired by Tim Ferriss, known 
for his focus on productivity and efficiency. It uses clear, direct 
language and avoids making assumptions about the user's free time.
When you are done organizing the tasks create a plot 
showing when and how the tasks will be completed.      #1
```

#1 This feature requires the Code Interpreter to be enabled.

Click the Create New Action button at the bottom of the panel. Figure 3.8 shows the interface for adding a custom action. You must copy and paste the OpenAPI specification for your service into the window. Then, you must add a new section called `servers` and populate that with your URL, as shown in the figure.

![figure](assets/3-8.png)

##### Figure 3.8 Adding a new custom action

After the specification is set, you can test it by clicking the Test button. This will run a test, and you’ll see the results shown in the conversation window, as shown in figure 3.9.

![figure](assets/3-9.png)

##### Figure 3.9 Testing the API service endpoint is correctly configured as a custom action

After you’re satisfied, everything is set. Refresh your browser window to reset the session, and enter something like the prompt shown in listing 3.15. This will prompt the agent to call the service to get your daily tasks, summarize the output, and solve your task organization dilemma.

##### Listing 3.15 Task Organizer prompt

```
how should I organize my tasks for today?
```

The assistant should produce a plot of the task schedule at the end. If it gets this wrong or the formatting isn’t what you prefer, you can add instructions to specify the format/style the assistant should output.

You can improve the service, but if you make any changes to the API, the specification in the assistant custom actions will need to be updated. From here, though, you can add custom action services run from your computer or hosted as a service.

Note  Be aware that unknown users can activate custom actions if you publish an assistant for public consumption, so don’t expose services that charge you a service fee or access private information unless that is your intention. Likewise, services opened through an ngrok tunnel will be exposed through the assistant, which may be of concern. Please be careful when publishing agents that consume custom actions.

Custom actions are a great way to add dynamic functionality to an assistant, whether for personal or commercial use. File uploads are a better option for providing an assistant with static knowledge. The next section will explore using file uploads to extend an assistant’s knowledge.

## 3.4 Extending an assistant’s knowledge using file uploads

If you’ve engaged with LLMs, you likely have heard about the retrieval augmented generation (RAG) pattern. Chapter 8 will explore RAG in detail for the application of both knowledge and memory. Detailed knowledge of RAG isn’t required to use the file upload capability, but if you need some foundation, check out that chapter.

The GPT Assistants platform provides a knowledge capability called *file uploads*, which allows you to populate the GPT with a static knowledge base about anything in various formats. As of writing, the GPT Assistants platform allows you to upload up to 512 MB of documents. In the next two exercises, we’ll look at two different GPTs designed to assist users with consuming books.

### 3.4.1 Building the Calculus Made Easy GPT

Books and written knowledge will always be the backbone of our knowledge base. But reading text is a full-time concerted effort many people don’t have time for. Audiobooks made consuming books again accessible; you could listen while multitasking, but not all books transitioned well to audio.

Enter the world of AI and intelligent assistants. With GPTs, we can create an interactive experience between the reader and the book. No longer is the reader forced to consume a book page by page but rather as a whole.

To demonstrate this concept, we’ll build a GPT based on a classic math text called *Calculus Made Easy*, by Silvanus P. Thompson. The book is freely available through the Gutenberg Press website. While it’s more than a hundred years old, it still provides a solid material background.

Note  If you’re serious about learning calculus but this assistant is still too advanced, check out a great book by Clifford A. Pickover called *Calculus and Pizza*. It’s a great book for learning calculus or just to get an excellent refresher. You could also try making your Calculus and Pizza assistant if you have an eBook version. Unfortunately, copyright laws would prevent you from publishing this GPT without permission.

Open ChatGPT, go to My GPTs, create a new GPT, click the Configure tab, and then upload the file, as shown in figure 3.10. Upload the book from the chapter’s source code folder: `chapter _03/calculus_made_easy.pdf`. This will add the book to the GPT’s knowledge.

![figure](assets/3-10.png)

##### Figure 3.10 Adding files to the assistant’s knowledge

Scroll up and add the instructions shown in listing 3.16. The initial preamble text was generated by conversing with the GPT Builder. After updating the preamble text, a personality was added by asking ChatGPT for famous mathematicians. Then, finally, rules were added to provide additional guidance to the GPT on what explicit outcomes we want.

##### Listing 3.16 Instructions for Calculus Made Easy GPT

```
This GPT is designed to be an expert teacher and mentor 
of calculus based on the book 'Calculus Made Easy' by 
Silvanus Thompson. A copy of the book is uploaded at 
calculus_made_easy.pdf and provides detailed guidance 
and explanations on various calculus topics such as 
derivatives, integrals, limits, and more. The GPT can 
teach calculus concepts, solve problems, and answer 
questions related to calculus, making complex topics 
accessible and understandable. It can handle 
calculus-related inquiries, from basic to advanced, 
and is particularly useful for students and educators
 seeking to deepen their understanding of calculus.      #1
Answer as the famous mathematician Terence Tao. 
Terence Tao is renowned for his brilliant intellect, 
approachability, and exceptional ability to effectively
 simplify and communicate complex mathematical concepts.     #2

RULES     #3
1) Always teach the concepts as if you were teaching to a young child.
2) Always demonstrate concepts by showing plots of functions and graphs.
3) Always ask if the user wants to try a sample problem on their own. 
Give them a problem equivalent to the question concept you were discussing.
```

#1 The preamble was initially generated by the Builder and then tweaked as needed.  
#2 Be sure always to give your assistants and agents an appropriate persona/personality.  
#3 Defining explicit conditions and rules can help better guide the GPT to your desire.

After updating the assistant, you can try it in the preview window or the book version by searching for Calculus Made Easy in the GPT Store. Figure 3.11 shows a snipped example of interaction with the GPT. The figure shows that the GPT can generate plots to demonstrate concepts or ask questions.

![figure](assets/3-11.png)

##### Figure 3.11 Output from asking the GPT to teach calculus

This GPT demonstrates the ability of an assistant to use a book as a companion teaching reference. Only a single book was uploaded in this exercise, but multiple books or other documents could be uploaded. As this feature and the technology mature, in the future, it may be conceivable that an entire course could be taught using a GPT.

We’ll move away from technical and embrace fiction to demonstrate the use of knowledge. In the next section, we’ll look at how knowledge of file uploads can be used for search and reference.

### 3.4.2 Knowledge search and more with file uploads

The GPT Assistants platform’s file upload capability supports up to 512 MB of uploads for a single assistant. This feature alone provides powerful capabilities for document search and other applications in personal and small-to-medium business/ project sizes.

Imagine uploading a whole collection of files. You can now search, compare, contrast, organize, and collate all with one assistant. This feature alone within GPT Assistants will disrupt how we search for and analyze documents. In chapter 6, we’ll examine how direct access to the OpenAI Assistants API can increase the number of documents.

For this next exercise, we’ll employ an assistant with knowledge of multiple books or documents. This technique could be applied to any supported document, but this assistant will consume classic texts about robots. We’ll name this assistant the Classic Robot Reads GPT.

Start by creating a new GPT assistant in the ChatGPT interface. Then, upload the instructions in listing 3.17, and name and describe the assistant. These instructions were generated in part through the GPT Builder and then edited.

##### Listing 3.17 Classic Robot Reads instructions

```
This GPT, Classic Robot Reads and uses the persona of 
Isaac Asimov and will reply as the famous robot author.     #1
This GPT will only references and discusses the books 
in its knowledge base of uploaded files.                   #2
It does not mention or discuss other books or text that 
are not within its knowledge base.                        #2

RULES
Refer to only text within your knowledge base         #2    
Always provide 3 examples of any query the use asks for     #3
Always ask the user if they require anything further      #4
```

#1 Remember always to give your GPT a persona/personality.  
#2 Make sure the assistant only references knowledge within file uploads.  
#3 Add some extra rules for style choices.  
#4 Make the assistant more helpful by also giving them nuance and style.

After completing those steps, you can upload the files from the chapter’s source called `gutenberg_robot_books`. Figure 3.12 demonstrates uploading multiple files at a time. The maximum number of files you can upload at a time will vary according to the sizes of the files.

![figure](assets/3-12.png)

##### Figure 3.12 Uploading documents to the assistant’s knowledge

You can start using it after uploading the documents, setting the instructions, and giving the assistant a name and an image. Search is the most basic application of a knowledge assistant, and other use cases in the form of prompts are shown in table 3.1.

##### Table 3.1 Use cases for a knowledge assistant

Use case

Example prompt

Results

Search  
Search for this phrase in your knowledge: “the robot servant.”  
Returns the document and an excerpt  
Compare  
Identify the three most similar books that share the same writing style.  
Returns the three most similar documents  
Contrast  
Identify the three most different books.  
Returns books in the collection that are the most different  
Ordering  
What order should I read the books?  
Returns an ordered progression of books  
Classification  
Which of these books is the most modern?  
Classifies documents  
Generation  
Generate a fictional paragraph that mimics your knowledge of the robot servant.  
Generates new content based on its knowledge base

These use cases are just a sample of the many things possible with an AI knowledge assistant. While this feature may not be poised to disrupt enterprise search, it gives smaller organizations and individuals more access to their documents. It allows the creation of assistants as a form of knowledge that can be exposed publicly. In the next section, we’ll look at how to make assistants consumable by all.

## 3.5 Publishing your GPT

Once you’re happy with your GPT, you can use it or share it with others by providing a link. Consuming GPT assistants through ChatGPT currently requires a Plus subscription. To publish your GPT for others, click the Share button, and select your sharing option, as shown in figure 3.13.

![figure](assets/3-13.png)

##### Figure 3.13 GPT sharing options

Whether you share your GPT with friends and colleagues or publicly in the GPT Store, the assistant’s usage is taken from the account using it, not the publisher. This means if you have a particularly expensive GPT that generates a lot of images, for example, it won’t affect your account while others use it.

### 3.5.1 Expensive GPT assistants

At the time of writing, OpenAI tracks the resource usage of your ChatGPT account, including that used for GPTs. If you hit a resource usage limit and get blocked, your ChatGPT account will also be blocked. Blockages typically only last a couple of hours, but this can undoubtedly be more than a little annoying.

Therefore, we want to ensure that users using your GPT don’t exceed their resource usage limits for regular use. Following is a list of features that increase resource usage while using the GPT:

- *Creating images* —Image generation is still a premium service, and successive image generation can quickly get your user blocked. It’s generally recommended that you inform your users of the potential risks and/or try to reduce how frequently images are generated.
- *Code interpretation* —This feature allows for file uploads and running of code for data analysis. If you think your users will require constant use of the coding tool, then inform them of the risk.
- *Vision, describing images* —If you’re building an assistant that uses vision to describe and extract information from the image, plan to use it sparingly.
- *File uploads* —If your GPT uses a lot of files or allows you to upload several files, this may cause blocks. As always, guide the user away from anything preventing them from enjoying your GPT.

Note  Moore’s Law states that computers will double in power every two years while costing half as much. LLMs are now doubling in power about every six months from optimization and increasing GPU power. This, combined with the cost being reduced by at least half in the same period, likely means current resource limits on vision and image-generation models won’t be considered. However, services such as code interpretation and file uploads will likely remain the same.

Making your assistant aware of resource usage can be as simple as adding the rule shown in listing 3.18 to the assistant’s instructions. The instructions can be just a statement relaying the warning to the user and making the assistant aware. You could even ask the assistant to limit its usage of certain features.

##### Listing 3.18 Resource usage rule example

```
RULE:
When generating images, ensure the user is aware that creating multiple 
images quickly could temporarily block their account.
```

Guiding your assistant to be more resource conscious in the end makes your assistant more usable. It also helps prevent angry users who unknowingly get blocked using your assistant. This may be important if you plan on releasing your GPT, but before that, let’s investigate the economics in the next section.

### 3.5.2 Understanding the economics of GPTs

Upon the release of GPT Assistants and the GPT Store, OpenAI announced the potential for a future profit-sharing program for those who published GPTs. While we’re still waiting to hear more about this program, many have speculated what this may look like.

Some have suggested the store may return only 10% to 20% of profits to the builders. This is far less than the percentage on other app platforms but requires much less technical knowledge and fewer resources. The GPT Store is flooded with essentially free assistants, provided you have a Plus subscription, but that may change in the future. Regardless, there are also several reasons why you may want to build public GPTs:

- *Personal portfolio* —Perhaps you want to demonstrate your knowledge of prompt engineering or your ability to build the next wave of AI applications. Having a few GPTs in the GPT Store can help demonstrate your knowledge and ability to create useful AI applications.
- *Knowledge and experience* —If you have in-depth knowledge of a subject or topic, this can be a great way to package that as an assistant. These types of assistants will vary in popularity based on your area of expertise.
- *Cross-marketing and commercial tie-in* —This is becoming more common in the Store and provides companies the ability to lead customers using an assistant. As companies integrate more AI, this will certainly be more common.
- *Helpful assistant to your product/service* —Not all companies or organizations can sustain the cost of hosting chatbots. While consuming assistants is currently limited to ChatGPT subscribers, they will likely be more accessible in the future. This may mean having GPTs for everything, perhaps like the internet’s early days where every company rushed to build a web presence.

While the current form of the GPT Store is for ChatGPT subscribers, if the current trend with OpenAI continues, we’ll likely see a fully public GPT Store. Public GPTs have the potential to disrupt the way we search, investigate products and services, and consume the internet. In the last section of this chapter, we’ll examine how to publish a GPT and some important considerations.

### 3.5.3 Releasing the GPT

Okay, you’re happy with your GPT and how it operates, and you see real benefit from giving it to others. Publishing GPTs for public (subscribers) consumption is easy, as shown in figure 3.14. After selecting the GPT Store as the option and clicking Save, you’ll now have the option to set the category and provide links back to you.

![figure](assets/3-14.png)

##### Figure 3.14 Selecting the options after clicking Save to publish to the GPT Store

That is easy, so here are a few more things you’ll want to consider before publishing your GPT:

- *GPT description* —Create a good description, and you may even want to ask ChatGPT to help you build a description that increases the search engine optimization (SEO) of your GPT. GPTs are now showing up in Google searches, so good search engine optimization can help increase exposure to your assistant. A good description will also help users decide if they want to take the time to use your assistant.
- *The logo* —A nice, clean logo that identifies what your assistant does can undoubtedly help. Logo design for GPTs is effectively a free service, but taking the time to iterate over a few images can help draw users to your assistant.
- *The category* —By default, the category will already be selected, but make sure it fits your assistant. If you feel it doesn’t, than change the category, and you may even want to select Other and define your own.
- *Links* —Be sure to set reference links for your social media and perhaps even a GitHub repository that you use to track problems for the GPT. Adding links to your GPT demonstrates to users that they can reach out to the builder if they encounter problems or have questions.

Further requirements may likely emerge as the GPT Store matures. The business model remains to be established, and other learnings will likely follow. Whether you decide to build GPTs for yourself or others, doing so can help improve your understanding of how to build agents and assistants. As we’ll see throughout the rest of this book, GPT assistants are a useful foundation for your knowledge.

## 3.6 Exercises

Complete the following exercises to improve your knowledge of the material:

- *Exercise 1* —Build Your First GPT Assistant

*Objective* —Create a simple GPT assistant using the ChatGPT interface.

*Tasks:*

- - Sign up for a ChatGPT Plus subscription if you don’t already have one.
  - Navigate to the GPT Assistants platform, and click the Create button.
  - Follow the Builder chat interface to create a Culinary Companion assistant that provides meal suggestions based on available ingredients.
  - Manually configure the assistant to add custom rules for recipe generation, such as including nutritional information and cost estimates.
- *Exercise 2* —Data Analysis Assistant

*Objective* —Develop a GPT assistant that can analyze CSV files and provide insights.

*Tasks:*

- - Design a data science assistant that can load and analyze CSV files, similar to the Data Scout example in the chapter.
  - Enable the Code Interpretation tool, and upload a sample CSV file (e.g., a dataset from Kaggle).
  - Use the assistant to perform tasks such as data cleaning, visualization, and hypothesis testing.
  - Document your process and findings, noting any challenges or improvements needed.
- *Exercise 3* —Create a Custom Action

*Objective* —Extend a GPT assistant with a custom action using a FastAPI service.

*Tasks:*

- - Follow the steps to create a FastAPI service that provides a specific function, such as fetching a list of daily tasks.
  - Generate the OpenAPI specification for the service, and deploy it locally using ngrok.
  - Configure a new assistant to use this custom action, ensuring it connects correctly to the FastAPI endpoint.
  - Test the assistant by asking it to perform the action and verify the output.
- *Exercise 4* —File Upload Knowledge Assistant

*Objective* —Build an assistant with specialized knowledge from uploaded documents.

*Tasks:*

- - Select a freely available e-book or a collection of documents related to a specific topic (e.g., classic literature, technical manuals).
  - Upload these files to a new GPT assistant, and configure the assistant to act as an expert on the uploaded content.
  - Create a series of prompts to test the assistant’s ability to reference and summarize the information from the documents.
  - Evaluate the assistant’s performance, and make any necessary adjustments to improve its accuracy and helpfulness.
- *Exercise 5* —Publish and Share Your Assistant

*Objective* —Publish your GPT assistant to the GPT Store and share it with others.

*Tasks:*

- - Finalize the configuration and testing of your assistant to ensure it works as intended.
  - Write a compelling description, and create an appropriate logo for your assistant.
  - Choose the correct category, and set up any necessary links to your social media or GitHub repository.
  - Publish the assistant to the GPT Store, and share the link with friends or colleagues.
  - Gather feedback from users, and refine the assistant based on their input to improve its usability and functionality.

## Summary

- The OpenAI GPT Assistants platform enables building and deploying AI agents through the ChatGPT UI, focusing on creating engaging and functional assistants.
- You can use GPT’s code interpretation capabilities to perform data analysis on user-uploaded CSV files, enabling assistants to function as data scientists.
- Assistants can be extended with custom actions, allowing integration with external services via API endpoints. This includes generating FastAPI services and their corresponding OpenAPI specifications.
- Assistants can be enriched with specialized knowledge through file uploads, allowing them to act as authoritative sources on specific texts or documents.
- Commercializing your GPT involves publishing it to the GPT Store, where you can share and market your assistant to a broader audience.
- Building a functional assistant involves iterating through design prompts, defining a clear persona, setting rules, and ensuring the assistant’s output aligns with user expectations.
- Creating custom actions requires understanding and implementing OpenAPI specifications, deploying services locally using tools such as ngrok, and connecting these services to your assistant.
- Knowledge assistants can handle various tasks, from searching and comparing documents to generating new content based on their knowledge base.
- Publishing assistants require careful consideration of resource usage, user experience, and economic factors to ensure their effectiveness and sustainability for public use.
- The GPT Store, available to ChatGPT Plus subscribers, is a valuable platform for learning and gaining proficiency in building AI assistants, with the potential for future profit-sharing opportunities.
